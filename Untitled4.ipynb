{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77aa770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sadi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/sadi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sadi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sadi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, v_measure_score\n",
    "from numpy import unique\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16ab887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=['K', 'linkage', 'affinity', 'reduction_type', 'silhouette_euclidian',\n",
    "                      'silhouette_cosine', 'silhouette_manhattan', 'calinski', \n",
    "                      'davies', 'time']).to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0d4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/concat.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf9bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_c = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_c.remove('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8fe464",
   "metadata": {},
   "outputs": [],
   "source": [
    "c['aaa'] = 100\n",
    "c['bbb'] = 20\n",
    "c['text'] = 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.drop(['aaa', 'bbb'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf49f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter notebook list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc85f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "??TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9791d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, stop_words):\n",
    "    x = x.lower()\n",
    "    x = re.sub('[0-9]|,|\\.|/|$|\\(|\\)|-|\\+|:|â€¢', ' ', x)\n",
    "      \n",
    "    if stop_words:\n",
    "        tokens = nltk.word_tokenize(x)\n",
    "        tokens = [lemmatizer.lemmatize(w, 'v') for w in tokens if not w.lower() in stopwords.words(\"english\")]\n",
    "        x = \" \".join(tokens)\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbf3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(text, min_df, max_df):\n",
    "    vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    return X, vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b57c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/concat.txt', header=None)\n",
    "df.rename(columns = {0:'text'}, inplace = True)\n",
    "df.drop(1, axis=1, inplace=True)\n",
    "df['clean'] = df.text.apply(lambda x: preprocess(x, True))\n",
    "X, terms = vectorizer(df.clean, 5, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=10).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d96c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ac07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Y_tsne = TSNE(n_components=2, random_state=18199).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbeb6f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b5b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10, random_state=18199)\n",
    "Y_pca = pca.fit_transform(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "451fc141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "709dc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AgglomerativeClustering(n_clusters=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a148c0d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:1054\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit and return the result of each sample's clustering assignment.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m    In addition to fitting, this method also return the result of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m        Cluster labels.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/base.py:736\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:917\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \n\u001b[1;32m    902\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m        Returns the fitted instance.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n",
      "File \u001b[0;32m/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/utils/validation.py:720\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[1;32m    719\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 720\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m/opt/envs/multi-env/lib/python3.10/site-packages/sklearn/utils/validation.py:440\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sparse matrix was passed, but dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is required. Use X.toarray() to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "ag.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634fe16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distor = []\n",
    "for i in range(2, 20):\n",
    "    print(f'Working with {i} clusters')\n",
    "    km = KMeans(n_clusters=i, max_iter=10000, n_init=100, random_state=61658)\n",
    "    distor.append(km.fit(X).inertia_)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range(2, 20), distor)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088c87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distor = []\n",
    "for i in range(2, 20):\n",
    "    print(f'Working with {i} clusters')\n",
    "    km = KMeans(n_clusters=i, max_iter=10000, n_init=100, random_state=61658)\n",
    "    distor.append(km.fit(X).inertia_)\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range(2, 20), distor)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1fd552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word(cluster, tokens, footnote=None):\n",
    "    words = ' '.join(tokens) + ' '\n",
    "    wordcloud = WordCloud(width=800, height=800, background_color='white', \n",
    "                          min_font_size=10).generate(words)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Cluster {cluster} top terms')\n",
    "    if footnote:\n",
    "        plt.figtext(.5, .05, text, fontsize=8, ha='center')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-env",
   "language": "python",
   "name": "multi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
